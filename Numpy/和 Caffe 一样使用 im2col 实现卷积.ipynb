{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 和 Caffe 一样使用 im2col 实现卷积\n",
    "\n",
    "2019 年 5 月 22 日\n",
    "\n",
    "首先实现 im2col.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def make_padding(input, padding=(0, 0)):\n",
    "    if padding == (0, 0):\n",
    "        return input\n",
    "    B, C, H, W = input.shape\n",
    "    pad = np.zeros((B, C, H + 2 * padding[0], W + 2 * padding[1]))\n",
    "    pad[..., padding[0]:-padding[0], padding[1]:-padding[1]] = input\n",
    "    return pad\n",
    "\n",
    "def make_dilation(input, dilation=(1, 1)):\n",
    "    if dilation == (1, 1):\n",
    "        return input\n",
    "    \n",
    "    B, C, H, W = input.shape\n",
    "    p, q = dilation\n",
    "    oh, ow = p * (H - 1) + 1, q * (W - 1) + 1\n",
    "    pad = np.zeros((B, C, oh, ow))\n",
    "    pad[..., ::p, ::q] = input\n",
    "    return pad\n",
    "\n",
    "def unwrap_padding(input, padding=(0, 0)):\n",
    "    if padding == (0, 0):\n",
    "        return input\n",
    "    p, q = padding\n",
    "    return input[..., p:-p, q:-q]\n",
    "\n",
    "\n",
    "def rotate_kernel(kernel):\n",
    "    return kernel[..., ::-1, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现 im2col\n",
    "\n",
    "输入 img 的 `shape=(N, C, h, w)`. 然后在考虑 stride 的情况下, 对图像上区域为 `img[n, :, i * s : i * s + kh, j * s : j * s + kw]` 的子块转换为行的形式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 3. 4.]\n",
      " [1. 2. 4. 5.]\n",
      " [3. 4. 6. 7.]\n",
      " [4. 5. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "def im2col(img, ksize, stride=(1, 1), dilation=(1, 1)):\n",
    "    N, C, h, w = img.shape\n",
    "    kh, kw = ksize\n",
    "    s, _ = stride\n",
    "    d, _ = dilation\n",
    "    oh, ow = (h - (d * (kh - 1) + 1)) // s + 1, (w - (d * (kw - 1) + 1)) // s + 1\n",
    "    x_col = np.zeros((N * oh * ow, C * kh * kw))\n",
    "    for idx in range(x_col.shape[0]):\n",
    "        n = idx // (oh * ow)\n",
    "        i, j = (idx - (n * oh * ow)) // ow, (idx - (n * oh * ow)) % ow\n",
    "        x_col[idx, :] = img[n, :, i * s : i * s + kh, j * s : j * s + kw].reshape(C * kh * kw)\n",
    "    return x_col\n",
    "\n",
    "\n",
    "p = 2\n",
    "s = 2\n",
    "d = 1\n",
    "\n",
    "h = w = 3\n",
    "kh = kw = 2\n",
    "N = 1\n",
    "C = 1\n",
    "oC = 1\n",
    "input = np.arange(N * C * h * w, dtype=np.float64).reshape(N, C, h, w)\n",
    "\n",
    "col = im2col(input, (kh, kw))\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过 im2col 实现卷积\n",
    "\n",
    "使用 im2col 实现卷积非常简单, 将问题转化为矩阵相乘, 先将图像转换为 `x_col`, 再将 kernel 也转换为 column 的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(input, kernel, p, s, d):\n",
    "    input = make_padding(input, (p, p))\n",
    "    \n",
    "    N, C, H, W = input.shape\n",
    "    iC, oC, kh, kw = kernel.shape\n",
    "    assert C == iC, 'channels not aligned'\n",
    "    \n",
    "    oh, ow = (H - (d * (kh - 1) + 1)) // s + 1, (W - (d * (kw - 1) + 1)) // s + 1\n",
    "    \n",
    "    x_col = im2col(input, (kh, kw), stride=(s, s), dilation=(d, d))\n",
    "    kernel_col = kernel.transpose(1, 0, 2, 3).reshape(oC, iC * kh * kw)\n",
    "    out = x_col @ kernel_col.T\n",
    "    return out.reshape(N, oC, oh, ow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反向传播的实现\n",
    "\n",
    "\n",
    "分为误差传播和梯度更新\n",
    "\n",
    "对于误差传播, 将 eta 中的每个值, 和 kernel 整体进行相乘, 具体的效果就是: `eta.reshape(N * oC * oh * ow, 1) * kernel.reshape(1, iC * oC * kh * kw)`, 然后使用 col2im 恢复结果, 在该函数中, 相当于 im2col 的逆过程, 但是相同位置的元素值是累加的. 此外, 注意 col2im 的参数有点多.\n",
    "\n",
    "而对于梯度更新, 就是经过 padding 的 input 和经过 dilation(=stride rate) 后的 eta 进行卷积, 对于 kernel 中的 $w_1$, 它的梯度是 input 中所有 N 个 batch 的第一个 patch 和 eta 中所有 N 个 batch 的第 1 个输出通道进行卷积, 相当于 `input[:, ic, dh, dw]` 与 `eta[:, oc, dh, dw]` 卷积. **注意限定 input 的范围, 即对 `input[:, :, :kh - 1 + dh, :kw - 1 + dw]` 范围内的输入进行卷积**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2im(col, N, isize, channels, osize, ksize, stride=(1, 1), dilation=(1, 1)):\n",
    "    h, w = isize\n",
    "    oh, ow = osize\n",
    "    kh, kw = ksize\n",
    "    s, _ = stride\n",
    "    d, _ = dilation\n",
    "    iC, oC = channels\n",
    "\n",
    "    img = np.zeros((N, iC, h, w))\n",
    "    for idx in range(col.shape[0]):\n",
    "        n = idx // (oC * oh * ow)\n",
    "        i, j = (idx - (n * oC * oh * ow)) // ow, (idx - (n * oC * oh * ow)) % ow\n",
    "        img[n, :, i * s : i * s + kh, j * s : j * s + kw] += col[idx].reshape(iC, -1, kh, kw).sum(axis=1)\n",
    "    return img\n",
    "\n",
    "def backward_conv(input, kernel, eta, p, s, d):\n",
    "    N, C, h, w = input.shape\n",
    "    iC, oC, kh, kw = kernel.shape\n",
    "    oh, ow = eta.shape[-2:]\n",
    "    input_grad = np.zeros_like(input)\n",
    "    kernel_grad = np.zeros_like(kernel)\n",
    "    \n",
    "    input_grad = make_padding(input_grad, (p, p))\n",
    "    ih, iw = input_grad.shape[-2:]\n",
    "    input_grad = eta.reshape(N * oC * oh * ow, 1) * kernel.reshape(1, iC * oC * kh * kw)\n",
    "    input_grad = col2im(input_grad, N, (ih, iw), (iC, oC), (oh, ow), (kh, kw), stride=(s, s), dilation=(d, d))\n",
    "    input_grad = unwrap_padding(input_grad, (p, p))\n",
    "    \n",
    "    input = make_padding(input, (p, p))\n",
    "    eta = make_dilation(eta, (s, s))\n",
    "    dh, dw = eta.shape[-2:]\n",
    "    x_col = im2col(input[:, :, :kh - 1 + dh, :kw - 1 + dw], (dh, dw)).reshape(N, C, -1, dh * dw).transpose(1, 2, 0, 3).reshape(-1, N * dh * dw)\n",
    "    eta_col = eta.transpose(1, 0, 2, 3).reshape(oC, -1)\n",
    "    kernel_grad = x_col @ eta_col.T\n",
    "    kernel_grad = kernel_grad.reshape(iC, kh, kw, oC).transpose(0, 3, 1, 2)\n",
    "    return input_grad, kernel_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  0.   0.   0.]\n",
      "   [  0. 312. 240.]\n",
      "   [  0. 304. 184.]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[0., 1., 2., 0., 1.],\n",
       "          [3., 4., 5., 3., 4.],\n",
       "          [6., 7., 8., 6., 7.],\n",
       "          [0., 1., 2., 0., 1.],\n",
       "          [3., 4., 5., 3., 4.]]]]), array([[[[36., 40., 19.],\n",
       "          [56., 60., 29.],\n",
       "          [23., 25., 12.]]]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 3\n",
    "s = 3\n",
    "d = 1\n",
    "\n",
    "h = w = 5\n",
    "kh = kw = 3\n",
    "N = 1\n",
    "C = 1\n",
    "oC = 1\n",
    "input = np.arange(N * C * h * w, dtype=np.float64).reshape(N, C, h, w)\n",
    "kernel = np.arange(C * oC * kh * kw, dtype=np.float64).reshape(C, oC, kh, kw)\n",
    "out_conv = conv(input, kernel, p, s, d) \n",
    "print(out_conv)\n",
    "eta = np.ones_like(out_conv)\n",
    "backward_conv(input, kernel, eta, p, s, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 PyTorch 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  0.,   0.,   0.],\n",
      "          [  0., 312., 240.],\n",
      "          [  0., 304., 184.]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "tensor([[[[0., 1., 2., 0., 1.],\n",
      "          [3., 4., 5., 3., 4.],\n",
      "          [6., 7., 8., 6., 7.],\n",
      "          [0., 1., 2., 0., 1.],\n",
      "          [3., 4., 5., 3., 4.]]]])\n",
      "tensor([[[[36., 40., 19.],\n",
      "          [56., 60., 29.],\n",
      "          [23., 25., 12.]]]])\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.arange(N * C * h * w).view(N, C, h, w).float(), requires_grad=True)\n",
    "net = nn.Conv2d(C, oC, (kh, kw), padding=p, stride=s, bias=False)\n",
    "shape = net.weight.data.size()\n",
    "net.weight.data.copy_(torch.arange(kh * kw).view(shape))\n",
    "# net.weight.data.copy_(torch.ones_like(net.weight.data))\n",
    "output = net(input)\n",
    "print(output)\n",
    "y = output.sum()\n",
    "# print(y)\n",
    "y.backward()\n",
    "print(input.grad)\n",
    "print(net.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
